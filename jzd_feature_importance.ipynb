{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to see which features are more important this is from 13 - classification week 2 activity 5\n",
    "# https://git.bootcampcontent.com/University-of-Denver/DU-VIRT-AI-PT-10-2023-U-LOLC/-/blob/main/01-Lesson-Plans/13-Classification/2/Activities/05-Ins_Random_Forest/Solved/random_forest_solution.ipynb?ref_type=heads\n",
    "# first I am going to link to Meredith's file \"mm_random_forest_regression\"\n",
    "# the following are the DF from the file: \n",
    "    # y_pred_regress_avail \n",
    "    # y_pred_regress_rating \n",
    "    # y_pred_regress_price \n",
    "\n",
    "# once you have the training and testing scores\n",
    "\n",
    "# below is the code that we used in our class: \n",
    "\n",
    "# clf = RandomForestClassifier(random_state=1, n_estimators=500).fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "# print(f'Training Score: {clf.score(X_train_scaled, y_train)}')\n",
    "# print(f'Testing Score: {clf.score(X_test_scaled, y_test)}')\n",
    "# Get the feature importance array\n",
    "# feature_importances = clf.feature_importances_\n",
    "# List the top 10 most important features\n",
    "# importances_sorted = sorted(zip(feature_importances, X.columns), reverse=True)\n",
    "# importances_sorted[:10]\n",
    "# Plot the feature importances\n",
    "# features = sorted(zip(X.columns, feature_importances), key = lambda x: x[1])\n",
    "# cols = [f[0] for f in features]\n",
    "# width = [f[1] for f in features]\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# fig.set_size_inches(8,6)\n",
    "# plt.margins(y=0.001)\n",
    "\n",
    "# ax.barh(y=cols, width=width)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Get the feature importance array\n",
    "# rf_regress_avail_model - this is your training model for the random forest \n",
    "\n",
    "feature_importances = rf_regress_avail_model.feature_importances_\n",
    "feature_importances = rf_regress_rating_model.feature_importances_\n",
    "feature_importances = rf_regress_price_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_sorted = sorted(zip(feature_importances, X_avail.columns), reverse=True)\n",
    "importances_sorted = sorted(zip(feature_importances, X_rating.columns), reverse=True)\n",
    "importances_sorted = sorted(zip(feature_importances, X_price.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the feature importances\n",
    "features = sorted(zip(X_avail.columns, feature_importances), key = lambda x: x[1])\n",
    "cols = [f[0] for f in features]\n",
    "width = [f[1] for f in features]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "fig.set_size_inches(8,6)\n",
    "plt.margins(y=0.001)\n",
    "\n",
    "ax.barh(y=cols, width=width)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = rf_regress_rating_model.feature_importances_\n",
    "\n",
    "importances_sorted = sorted(zip(feature_importances, X_rating.columns), reverse=True)\n",
    "importances_sorted[:10]\n",
    "# Plot the feature importances\n",
    "features = sorted(zip(X_rating.columns, feature_importances), key = lambda x: x[1])\n",
    "cols = [f[0] for f in features]\n",
    "width = [f[1] for f in features]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "fig.set_size_inches(8,6)\n",
    "plt.margins(y=0.001)\n",
    "\n",
    "ax.barh(y=cols, width=width)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_importances = rf_regress_price_model.feature_importances_\n",
    "importances_sorted = sorted(zip(feature_importances, X_price.columns), reverse=True)\n",
    "importances_sorted[:10]\n",
    "# Plot the feature importances\n",
    "features = sorted(zip(X_price.columns, feature_importances), key = lambda x: x[1])\n",
    "cols = [f[0] for f in features]\n",
    "width = [f[1] for f in features]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "fig.set_size_inches(8,6)\n",
    "plt.margins(y=0.001)\n",
    "\n",
    "ax.barh(y=cols, width=width)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
